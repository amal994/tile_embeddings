{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44679ad9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mjson\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m shuffle\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m sequence, image\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimage\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m array_to_img, save_img, img_to_array\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.utils import shuffle\n",
    "from keras.preprocessing import sequence, image\n",
    "from keras.preprocessing.image import array_to_img, save_img, img_to_array\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from keras import metrics\n",
    "from keras.layers import (\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Input,\n",
    "    Activation,\n",
    "    BatchNormalization,\n",
    "    Conv2D,\n",
    "    MaxPool2D,\n",
    "    Dropout,\n",
    "    UpSampling2D,\n",
    "    Lambda,\n",
    ")\n",
    "\n",
    "import pickle\n",
    "from keras.layers import ReLU, Reshape, Conv2DTranspose, Concatenate, Multiply\n",
    "from keras.models import Model\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy, categorical_crossentropy\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from collections import Counter\n",
    "from keras import metrics\n",
    "from notebook_utils import initialize_environment\n",
    "initialize_environment()\n",
    "\n",
    "from utils.data_loading.load_data import get_tile_data\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from ast import literal_eval\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dc52985",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_directory = \"../data/context_data/\"\n",
    "json_directory = \"../data/json_files_trimmed_features/\"\n",
    "\n",
    "game_data_path=\"../data/game_data.csv\"\n",
    "train_data_path=\"../data/train_data.csv\"\n",
    "test_data_path=\"../data/test_data.csv\"\n",
    "\n",
    "EPOCHS=10\n",
    "BATCH_SIZE=25\n",
    "LATENT_DIM=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02b293d3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def loss_func_image(y_true, y_pred):\n",
    "    # tile sprite loss\n",
    "    r_loss=K.mean(K.square(y_true - y_pred), axis=[1,2,3])\n",
    "    loss  =  r_loss\n",
    "    return loss\n",
    "    \n",
    "def loss_func_text(y_true,y_pred):\n",
    "    # multilabel text weighted bce\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    bce_array=-(y_true*K.log(y_pred)+(1-y_true)*K.log(1-y_pred))\n",
    "    weighted_array=bce_array*tensor_from_list\n",
    "    bce_sum=K.sum(weighted_array,axis=1)\n",
    "    loss=bce_sum/13.0\n",
    "    return loss\n",
    "\n",
    "def check_nonzero(y_true,y_pred):\n",
    "    \"\"\"\n",
    "    Custom metric\n",
    "    Returns sum of all embeddings\n",
    "    \"\"\"\n",
    "    return(K.sum(K.cast(y_pred > 0.4, 'int32')))\n",
    "\n",
    "def get_pickle_file(path):\n",
    "    with open(path,\"rb\") as handle:\n",
    "        return pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11ec3c8c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Dictionary Loaded\n",
      "The feature dictionary has size 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Features'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['block', 'breakable', 'climbable', 'collectable', 'element',\n",
       "       'empty', 'hazard', 'moving', 'openable', 'passable', 'pipe',\n",
       "       'solid', 'wall'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Training Testing Batches loaded\n",
      "Train Image batch shape (18494, 48, 48, 3)\n",
      "Train Text batch shape (18494, 13)\n",
      "Train Output Image batch shape (18494, 16, 16, 3)\n",
      "Train Output Text batch shape (18494, 13)\n",
      "Test Image batch shape (2055, 48, 48, 3)\n",
      "Test Text batch shape (2055, 13)\n"
     ]
    }
   ],
   "source": [
    "# data loading\n",
    "data=pd.read_csv(game_data_path)\n",
    "train_data=pd.read_csv(train_data_path)\n",
    "test_data=pd.read_csv(test_data_path)\n",
    "\n",
    "data['features'] = data.features.apply(lambda x: literal_eval(str(x)))\n",
    "train_data['features'] = train_data.features.apply(lambda x: literal_eval(str(x)))\n",
    "test_data['features'] = test_data.features.apply(lambda x: literal_eval(str(x)))\n",
    "\n",
    "# loading multi-label binarizer\n",
    "mlb=get_pickle_file(\"../model/model_tokenizer.pickle\")\n",
    "print(\"Feature Dictionary Loaded\")\n",
    "total_features = len(mlb.classes_)\n",
    "print(\"The feature dictionary has size\", total_features)\n",
    "display(\"Features\", mlb.classes_)\n",
    "\n",
    "# loading the batches\n",
    "# training \n",
    "train_image_batch=get_pickle_file(\"../data/train_image_batch.pickle\")\n",
    "train_text_batch=get_pickle_file(\"../data/train_text_batch.pickle\")\n",
    "output_image_batch=get_pickle_file(\"../data/output_image_batch.pickle\")\n",
    "output_text_batch=get_pickle_file(\"../data/output_text_batch.pickle\")\n",
    "\n",
    "#testing\n",
    "test_image_batch=get_pickle_file(\"../data/test_image_batch.pickle\")\n",
    "test_text_batch=get_pickle_file(\"../data/test_text_batch.pickle\")\n",
    "\n",
    "print(\"\\Training Testing Batches loaded\")\n",
    "\n",
    "print(\"Train Image batch shape\", train_image_batch.shape)\n",
    "print(\"Train Text batch shape\", train_text_batch.shape)\n",
    "print(\"Train Output Image batch shape\", output_image_batch.shape)\n",
    "print(\"Train Output Text batch shape\", output_text_batch.shape)\n",
    "\n",
    "print(\"Test Image batch shape\", test_image_batch.shape)\n",
    "print(\"Test Text batch shape\", test_text_batch.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "476bdaa5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Printing the TF-IDF for the labels\n",
      "\n",
      " {'block': 4.895666560876659, 'breakable': 2.527712174910271, 'climbable': 2.7397689321637086, 'collectable': 4.067161199838823, 'element': 5.357195563131423, 'empty': 2.0458521063722053, 'hazard': 4.6853711520402985, 'moving': 5.965443299904882, 'openable': 6.220085518278463, 'passable': 1.5640321219758018, 'pipe': 6.190526716036919, 'solid': 1.8879058559991626, 'wall': 5.050704158722146}\n",
      "\n",
      "Printing the weight normalised\n",
      "\n",
      "\n",
      "{'block': 0.09202826128752296, 'breakable': 0.04751568629106969, 'climbable': 0.051501908477902945, 'collectable': 0.07645409852631353, 'element': 0.10070403834119256, 'empty': 0.038457727841484414, 'hazard': 0.08807514875600009, 'moving': 0.11213781981942068, 'openable': 0.11692455934016166, 'passable': 0.029400522889674464, 'pipe': 0.11636891586603913, 'solid': 0.03548866967178095, 'wall': 0.09494264289143667}\n",
      "Metal device set to: Apple M1\n",
      "Weight Vector\n",
      "[4895.666560876659, 2527.7121749102707, 2739.7689321637085, 4067.1611998388234, 5357.195563131423, 2045.8521063722053, 4685.3711520402985, 5965.443299904882, 6220.085518278463, 1564.0321219758018, 6190.5267160369185, 1887.9058559991627, 5050.7041587221465]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-09 07:31:19.752736: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-09-09 07:31:19.752840: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "#initialise the TF-IDF vectorizer to counter imbalanced dataset\n",
    "vectorizer = TfidfVectorizer(stop_words=None)\n",
    "train_data_copy = train_data\n",
    "train_data_copy[\"features\"] = train_data_copy.features.apply(lambda x: str(x))\n",
    "vectors = vectorizer.fit_transform(train_data_copy[\"features\"])\n",
    "idf = vectorizer.idf_\n",
    "new_dict = {}\n",
    "for c in mlb.classes_:\n",
    "    if c in vectorizer.vocabulary_.keys():\n",
    "        new_dict[c] = idf[vectorizer.vocabulary_[c]]\n",
    "    else:\n",
    "        new_dict[c] = np.max(idf)\n",
    "print(\"\\n Printing the TF-IDF for the labels\\n\\n\", new_dict)\n",
    "weight_freq = {k: v / sum(new_dict.values()) for k, v in new_dict.items()}\n",
    "print(\"\\nPrinting the weight normalised\\n\\n\")\n",
    "print(weight_freq)\n",
    "weight_vector = [v * 1000 for v in new_dict.values()]\n",
    "tensor_from_list = tf.convert_to_tensor(weight_vector)\n",
    "tensor_from_list = K.cast(tensor_from_list, \"float32\")\n",
    "print(\"Weight Vector\")\n",
    "print(weight_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b240e21b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model definition\n",
    "latent_dim = 128\n",
    "batch_size = 1\n",
    "# image encoder\n",
    "image_encoder_input = Input(shape=(48, 48, 3), name=\"image_input\")\n",
    "image_encoder_conv_layer1 = Conv2D(\n",
    "    32, strides=3, kernel_size=(3, 3), name=\"iencode_conv1\"\n",
    ")(image_encoder_input)\n",
    "image_encoder_norm_layer1 = BatchNormalization()(image_encoder_conv_layer1)\n",
    "image_encoder_actv_layer1 = ReLU()(image_encoder_norm_layer1)\n",
    "image_encoder_conv_layer2 = Conv2D(32, (3, 3), padding=\"same\", name=\"iencode_conv2\")(\n",
    "    image_encoder_actv_layer1\n",
    ")\n",
    "image_encoder_norm_layer2 = BatchNormalization()(image_encoder_conv_layer2)\n",
    "image_encoder_actv_layer2 = ReLU()(image_encoder_norm_layer2)\n",
    "image_encoder_conv_layer3 = Conv2D(16, (3, 3), padding=\"same\", name=\"iencode_conv3\")(\n",
    "    image_encoder_actv_layer2\n",
    ")\n",
    "image_encoder_norm_layer3 = BatchNormalization()(image_encoder_conv_layer3)\n",
    "image_encoder_actv_layer3 = ReLU()(image_encoder_norm_layer3)\n",
    "image_shape_before_flatten = K.int_shape(image_encoder_actv_layer3)[1:]\n",
    "image_flatten = Flatten(name=\"image_flatten_layer\")(image_encoder_actv_layer3)\n",
    "\n",
    "# text encoder\n",
    "text_encoder_input = Input(shape=(13,))\n",
    "text_encoder_dense_layer1 = Dense(32, activation=\"tanh\", name=\"tencode_dense1\")(\n",
    "    text_encoder_input\n",
    ")\n",
    "text_encoder_dense_layer2 = Dense(16, activation=\"tanh\", name=\"tencode_dense2\")(\n",
    "    text_encoder_dense_layer1\n",
    ")\n",
    "text_shape_before_concat = K.int_shape(text_encoder_dense_layer2)[1:]\n",
    "\n",
    "# image-text concatenation\n",
    "image_text_concat = Concatenate(name=\"image_text_concatenation\")(\n",
    "    [image_flatten, text_encoder_dense_layer2]\n",
    ")\n",
    "image_text_concat = Dense(256, activation=\"tanh\", name=\"embedding_dense_1\")(\n",
    "    image_text_concat\n",
    ")\n",
    "\n",
    "\n",
    "# define encoder model\n",
    "encoding_model = Model(\n",
    "    inputs=[image_encoder_input, text_encoder_input], outputs=image_text_concat\n",
    ")\n",
    "\n",
    "# decoder for image\n",
    "# decoder_input=Input(shape=(512,))\n",
    "image_y = Dense(units=np.prod(image_shape_before_flatten), name=\"image_dense\")(\n",
    "    image_text_concat\n",
    ")\n",
    "image_y = Reshape(target_shape=image_shape_before_flatten, name=\"image_reshape\")(\n",
    "    image_y\n",
    ")\n",
    "image_decoder_convt_layer1 = Conv2DTranspose(\n",
    "    16, (3, 3), padding=\"same\", name=\"idecode_conv1\"\n",
    ")(image_y)\n",
    "image_decoder_norm_layer1 = BatchNormalization(name=\"idecode_norm1\")(\n",
    "    image_decoder_convt_layer1\n",
    ")\n",
    "image_decoder_actv_layer1 = ReLU(name=\"idecode_relu1\")(image_decoder_norm_layer1)\n",
    "image_decoder_convt_layer2 = Conv2DTranspose(\n",
    "    32, (3, 3), padding=\"same\", name=\"idecode_conv2\"\n",
    ")(image_decoder_actv_layer1)\n",
    "image_decoder_norm_layer2 = BatchNormalization(name=\"idecode_norm2\")(\n",
    "    image_decoder_convt_layer2\n",
    ")\n",
    "image_decoder_actv_layer2 = ReLU(name=\"idecode_relu2\")(image_decoder_norm_layer2)\n",
    "image_decoder_output = Conv2DTranspose(\n",
    "    3, (3, 3), padding=\"same\", name=\"image_output_layer\"\n",
    ")(image_decoder_actv_layer2)\n",
    "\n",
    "\n",
    "# decoder for text\n",
    "text_decoder_dense_layer1 = Dense(16, activation=\"tanh\", name=\"tdecode_dense1\")(\n",
    "    image_text_concat\n",
    ")\n",
    "text_reshape = Reshape(target_shape=text_shape_before_concat, name=\"text_reshape\")(\n",
    "    text_decoder_dense_layer1\n",
    ")\n",
    "text_decoder_dense_layer2 = Dense(32, activation=\"tanh\", name=\"tdecode_dense2\")(\n",
    "    text_reshape\n",
    ")\n",
    "text_decoder_output = Dense(13, activation=\"sigmoid\", name=\"text_output_layer\")(\n",
    "    text_decoder_dense_layer2\n",
    ")\n",
    "# decoding_model=Model(inputs=[decoder_input],outputs=[image_decoder_output,text_decoder_output])\n",
    "\n",
    "ae_sep_output = Model(\n",
    "    [image_encoder_input, text_encoder_input],\n",
    "    [image_decoder_output, text_decoder_output],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b877ac7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-09 07:31:28.619179: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-09-09 07:31:28.619410: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-09 07:31:37.838757: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - ETA: 0s - loss: 1689.8965 - image_output_layer_loss: 8858.6509 - text_output_layer_loss: 893.3685 - image_output_layer_loss_func_image: 8858.6512 - text_output_layer_check_nonzero: 59.9411"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-09 07:31:48.113921: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - 21s 19ms/step - loss: 1689.0060 - image_output_layer_loss: 8854.0172 - text_output_layer_loss: 892.8939 - image_output_layer_loss_func_image: 8854.0175 - text_output_layer_check_nonzero: 59.9233 - val_loss: 569.9338 - val_image_output_layer_loss: 2852.4338 - val_text_output_layer_loss: 316.3228 - val_image_output_layer_loss_func_image: 2852.4338 - val_text_output_layer_check_nonzero: 44.2432\n",
      "Epoch 2/10\n",
      "592/592 [==============================] - 11s 18ms/step - loss: 451.3461 - image_output_layer_loss: 2359.4762 - text_output_layer_loss: 239.3315 - image_output_layer_loss_func_image: 2359.4762 - text_output_layer_check_nonzero: 44.3932 - val_loss: 275.3939 - val_image_output_layer_loss: 1574.3854 - val_text_output_layer_loss: 131.0616 - val_image_output_layer_loss_func_image: 1574.3855 - val_text_output_layer_check_nonzero: 46.2297\n",
      "Epoch 3/10\n",
      "592/592 [==============================] - 11s 18ms/step - loss: 263.1439 - image_output_layer_loss: 1623.4912 - text_output_layer_loss: 111.9943 - image_output_layer_loss_func_image: 1623.4912 - text_output_layer_check_nonzero: 46.5777 - val_loss: 194.0154 - val_image_output_layer_loss: 1251.1981 - val_text_output_layer_loss: 76.5508 - val_image_output_layer_loss_func_image: 1251.1981 - val_text_output_layer_check_nonzero: 46.4122\n",
      "Epoch 4/10\n",
      "592/592 [==============================] - 11s 19ms/step - loss: 189.3197 - image_output_layer_loss: 1316.5263 - text_output_layer_loss: 64.0745 - image_output_layer_loss_func_image: 1316.5263 - text_output_layer_check_nonzero: 46.5432 - val_loss: 138.7811 - val_image_output_layer_loss: 970.1994 - val_text_output_layer_loss: 46.4012 - val_image_output_layer_loss_func_image: 970.1994 - val_text_output_layer_check_nonzero: 46.1622\n",
      "Epoch 5/10\n",
      "592/592 [==============================] - 11s 18ms/step - loss: 137.2051 - image_output_layer_loss: 1021.6048 - text_output_layer_loss: 38.9385 - image_output_layer_loss_func_image: 1021.6048 - text_output_layer_check_nonzero: 46.5079 - val_loss: 117.8040 - val_image_output_layer_loss: 920.4296 - val_text_output_layer_loss: 28.6233 - val_image_output_layer_loss_func_image: 920.4296 - val_text_output_layer_check_nonzero: 46.5068\n",
      "Epoch 6/10\n",
      "592/592 [==============================] - 11s 18ms/step - loss: 115.1013 - image_output_layer_loss: 925.1456 - text_output_layer_loss: 25.0964 - image_output_layer_loss_func_image: 925.1456 - text_output_layer_check_nonzero: 46.7198 - val_loss: 88.7267 - val_image_output_layer_loss: 705.7574 - val_text_output_layer_loss: 20.1678 - val_image_output_layer_loss_func_image: 705.7574 - val_text_output_layer_check_nonzero: 46.5000\n",
      "Epoch 7/10\n",
      "592/592 [==============================] - 11s 18ms/step - loss: 92.5284 - image_output_layer_loss: 774.2832 - text_output_layer_loss: 16.7779 - image_output_layer_loss_func_image: 774.2832 - text_output_layer_check_nonzero: 46.6418 - val_loss: 93.6500 - val_image_output_layer_loss: 789.6387 - val_text_output_layer_loss: 16.3179 - val_image_output_layer_loss_func_image: 789.6387 - val_text_output_layer_check_nonzero: 46.5203\n",
      "Epoch 8/10\n",
      "592/592 [==============================] - 11s 18ms/step - loss: 81.3672 - image_output_layer_loss: 698.8076 - text_output_layer_loss: 12.7628 - image_output_layer_loss_func_image: 698.8076 - text_output_layer_check_nonzero: 46.7475 - val_loss: 66.9995 - val_image_output_layer_loss: 562.9968 - val_text_output_layer_loss: 11.8887 - val_image_output_layer_loss_func_image: 562.9968 - val_text_output_layer_check_nonzero: 46.5338\n",
      "Epoch 9/10\n",
      "592/592 [==============================] - 11s 18ms/step - loss: 67.3362 - image_output_layer_loss: 581.3691 - text_output_layer_loss: 10.2215 - image_output_layer_loss_func_image: 581.3691 - text_output_layer_check_nonzero: 46.8407 - val_loss: 57.3726 - val_image_output_layer_loss: 482.6133 - val_text_output_layer_loss: 10.1236 - val_image_output_layer_loss_func_image: 482.6134 - val_text_output_layer_check_nonzero: 46.4459\n",
      "Epoch 10/10\n",
      "592/592 [==============================] - 11s 18ms/step - loss: 58.7479 - image_output_layer_loss: 511.6548 - text_output_layer_loss: 8.4249 - image_output_layer_loss_func_image: 511.6548 - text_output_layer_check_nonzero: 46.6550 - val_loss: 52.2388 - val_image_output_layer_loss: 456.4069 - val_text_output_layer_loss: 7.3312 - val_image_output_layer_loss_func_image: 456.4069 - val_text_output_layer_check_nonzero: 46.4865\n"
     ]
    }
   ],
   "source": [
    "losses ={'image_output_layer':loss_func_image,\n",
    "          'text_output_layer':loss_func_text,\n",
    "}\n",
    "#tweak loss weights\n",
    "lossWeights={'image_output_layer':0.1,\n",
    "          'text_output_layer':0.9  \n",
    "        }\n",
    "\n",
    "\n",
    "accuracy={\n",
    "    'image_output_layer':loss_func_image,\n",
    "    'text_output_layer': check_nonzero\n",
    "}\n",
    "\n",
    "ae_sep_output.compile(\n",
    "    optimizer=\"adam\", loss=losses, loss_weights=lossWeights, metrics=accuracy\n",
    ")\n",
    "\n",
    "es = EarlyStopping(\n",
    "    monitor=\"val_text_output_layer_loss\", mode=\"min\", verbose=1, patience=2\n",
    ")\n",
    "\n",
    "ae_history = ae_sep_output.fit(\n",
    "    [train_image_batch, train_text_batch],\n",
    "    [output_image_batch, output_text_batch],\n",
    "    epochs=10,\n",
    "    batch_size=25,\n",
    "    shuffle=True,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[es],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a716e07",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "592/592 [==============================] - 11s 18ms/step - loss: 51.9090 - image_output_layer_loss: 465.7723 - text_output_layer_loss: 5.9241 - image_output_layer_loss_func_image: 465.7723 - text_output_layer_check_nonzero: 46.6723 - val_loss: 49.7016 - val_image_output_layer_loss: 436.4905 - val_text_output_layer_loss: 6.7251 - val_image_output_layer_loss_func_image: 436.4905 - val_text_output_layer_check_nonzero: 46.5473\n",
      "Epoch 2/5\n",
      "592/592 [==============================] - 11s 18ms/step - loss: 47.1144 - image_output_layer_loss: 423.9874 - text_output_layer_loss: 5.2397 - image_output_layer_loss_func_image: 423.9874 - text_output_layer_check_nonzero: 46.6723 - val_loss: 55.2789 - val_image_output_layer_loss: 441.1127 - val_text_output_layer_loss: 12.4084 - val_image_output_layer_loss_func_image: 441.1127 - val_text_output_layer_check_nonzero: 46.4392\n",
      "Epoch 3/5\n",
      "592/592 [==============================] - 11s 18ms/step - loss: 55.8166 - image_output_layer_loss: 480.3064 - text_output_layer_loss: 8.6511 - image_output_layer_loss_func_image: 480.3064 - text_output_layer_check_nonzero: 46.6334 - val_loss: 41.5654 - val_image_output_layer_loss: 359.3868 - val_text_output_layer_loss: 6.2519 - val_image_output_layer_loss_func_image: 359.3868 - val_text_output_layer_check_nonzero: 46.5405\n",
      "Epoch 4/5\n",
      "592/592 [==============================] - 11s 18ms/step - loss: 41.7013 - image_output_layer_loss: 370.4573 - text_output_layer_loss: 5.1729 - image_output_layer_loss_func_image: 370.4573 - text_output_layer_check_nonzero: 46.6115 - val_loss: 60.9125 - val_image_output_layer_loss: 556.4233 - val_text_output_layer_loss: 5.8558 - val_image_output_layer_loss_func_image: 556.4234 - val_text_output_layer_check_nonzero: 46.4662\n",
      "Epoch 5/5\n",
      "592/592 [==============================] - 11s 18ms/step - loss: 36.9564 - image_output_layer_loss: 340.3987 - text_output_layer_loss: 3.2406 - image_output_layer_loss_func_image: 340.3987 - text_output_layer_check_nonzero: 46.5997 - val_loss: 35.6880 - val_image_output_layer_loss: 327.4654 - val_text_output_layer_loss: 3.2683 - val_image_output_layer_loss_func_image: 327.4654 - val_text_output_layer_check_nonzero: 46.4189\n"
     ]
    }
   ],
   "source": [
    "ae_history = ae_sep_output.fit(\n",
    "    [train_image_batch, train_text_batch],\n",
    "    [output_image_batch, output_text_batch],\n",
    "    epochs=5,\n",
    "    batch_size=25,\n",
    "    shuffle=True,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[es],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dc34a03",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# build the inference model\n",
    "\n",
    "decoder_input = Input(shape=(256,))\n",
    "\n",
    "d_dense = ae_sep_output.get_layer(\"image_dense\")(decoder_input)\n",
    "d_reshape = ae_sep_output.get_layer(\"image_reshape\")(d_dense)\n",
    "d_conv1 = ae_sep_output.get_layer(\"idecode_conv1\")(d_reshape)\n",
    "d_norm1 = ae_sep_output.get_layer(\"idecode_norm1\")(d_conv1)\n",
    "d_relu1 = ae_sep_output.get_layer(\"idecode_relu1\")(d_norm1)\n",
    "d_conv2 = ae_sep_output.get_layer(\"idecode_conv2\")(d_relu1)\n",
    "d_norm2 = ae_sep_output.get_layer(\"idecode_norm2\")(d_conv2)\n",
    "d_relu2 = ae_sep_output.get_layer(\"idecode_relu2\")(d_norm2)\n",
    "d_image_output = ae_sep_output.get_layer(\"image_output_layer\")(d_relu2)\n",
    "\n",
    "t_dense = ae_sep_output.get_layer(\"tdecode_dense1\")(decoder_input)\n",
    "t_reshape = ae_sep_output.get_layer(\"text_reshape\")(t_dense)\n",
    "t_dense2 = ae_sep_output.get_layer(\"tdecode_dense2\")(t_reshape)\n",
    "d_text_output = ae_sep_output.get_layer(\"text_output_layer\")(t_dense2)\n",
    "\n",
    "decoder_model = Model(inputs=[decoder_input], outputs=[d_image_output, d_text_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bca7d108",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Entire Model to disk\n",
      "Saved Encoder Model to disk\n",
      "Saved Decoder Model to disk\n"
     ]
    }
   ],
   "source": [
    "# saving the entire architecture model\n",
    "model_json = ae_sep_output.to_json()\n",
    "with open(\"../model/autoencoder_model_test.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "ae_sep_output.save_weights(\"../model/autoencoder_model_test.h5\")\n",
    "print(\"Saved Entire Model to disk\")\n",
    "\n",
    "# saving the encoder part\n",
    "model_json = encoding_model.to_json()\n",
    "with open(\"../model/encoder_model_test.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "encoding_model.save_weights(\"../model/encoder_model_test.h5\")\n",
    "print(\"Saved Encoder Model to disk\")\n",
    "# saving the encoder part\n",
    "\n",
    "model_json = decoder_model.to_json()\n",
    "with open(\"../model/decoder_model_test.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "decoder_model.save_weights(\"../model/decoder_model_test.h5\")\n",
    "print(\"Saved Decoder Model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fd8d23",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a55e09",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}