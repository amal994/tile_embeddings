{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dd53ac1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "import json\n",
    "from keras.preprocessing import sequence, image\n",
    "from keras.preprocessing.image import array_to_img, save_img, img_to_array\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from collections import Counter\n",
    "\n",
    "from notebook_utils import initialize_environment\n",
    "initialize_environment()\n",
    "\n",
    "from utils.evaluation_metrics.multilabel.example_based import (\n",
    "    hamming_loss,\n",
    "    example_based_accuracy,\n",
    "    example_based_precision,\n",
    "    example_based_recall,\n",
    ")\n",
    "\n",
    "from utils.evaluation_metrics.multilabel.label_based import (\n",
    "    accuracy_macro,\n",
    "    precision_macro,\n",
    "    recall_macro,\n",
    "    accuracy_micro,\n",
    "    precision_micro,\n",
    "    recall_micro,\n",
    ")\n",
    "from ast import literal_eval\n",
    "from utils.evaluation_metrics.multilabel.alpha_score import alpha_score\n",
    "from utils.data_loading.load_data import get_tile_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dac9a244",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_directory = \"../data/context_data/\"\n",
    "json_directory = \"../data/json_files_trimmed_features/\"\n",
    "\n",
    "game_data_path=\"../data/game_data.csv\"\n",
    "train_data_path=\"../data/train_data.csv\"\n",
    "test_data_path=\"../data/test_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bed1663",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_pickle_file(path):\n",
    "    with open(path,\"rb\") as handle:\n",
    "        return pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e98f5194",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Dictionary Loaded\n",
      "The feature dictionary has size 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Features'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['agent', 'ball', 'can_overlap', 'can_pickup', 'can_see_behind',\n",
       "       'door', 'empty', 'goal', 'is_locked', 'key', 'lava', 'wall'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Training Testing Batches loaded\n",
      "Train Image batch shape (99759, 48, 48, 3)\n",
      "Train Text batch shape (99759, 12)\n",
      "Train Output Image batch shape (99759, 16, 16, 3)\n",
      "Train Output Text batch shape (99759, 12)\n",
      "Test Image batch shape (9810, 48, 48, 3)\n",
      "Test Text batch shape (9810, 12)\n"
     ]
    }
   ],
   "source": [
    "# data loading\n",
    "data=pd.read_csv(game_data_path)\n",
    "train_data=pd.read_csv(train_data_path)\n",
    "test_data=pd.read_csv(test_data_path)\n",
    "\n",
    "data['features'] = data.features.apply(lambda x: literal_eval(str(x)))\n",
    "train_data['features'] = train_data.features.apply(lambda x: literal_eval(str(x)))\n",
    "test_data['features'] = test_data.features.apply(lambda x: literal_eval(str(x)))\n",
    "\n",
    "# loading multi-label binarizer\n",
    "mlb=get_pickle_file(\"../model/model_tokenizer.pickle\")\n",
    "print(\"Feature Dictionary Loaded\")\n",
    "total_features = len(mlb.classes_)\n",
    "print(\"The feature dictionary has size\", total_features)\n",
    "display(\"Features\", mlb.classes_)\n",
    "\n",
    "# loading the batches\n",
    "# training \n",
    "train_image_batch=get_pickle_file(\"../data/train_image_batch.pickle\")\n",
    "train_text_batch=get_pickle_file(\"../data/train_text_batch.pickle\")\n",
    "output_image_batch=get_pickle_file(\"../data/output_image_batch.pickle\")\n",
    "output_text_batch=get_pickle_file(\"../data/output_text_batch.pickle\")\n",
    "\n",
    "#testing\n",
    "test_image_batch=get_pickle_file(\"../data/test_image_batch.pickle\")\n",
    "test_text_batch=get_pickle_file(\"../data/test_text_batch.pickle\")\n",
    "\n",
    "print(\"\\Training Testing Batches loaded\")\n",
    "\n",
    "print(\"Train Image batch shape\", train_image_batch.shape)\n",
    "print(\"Train Text batch shape\", train_text_batch.shape)\n",
    "print(\"Train Output Image batch shape\", output_image_batch.shape)\n",
    "print(\"Train Output Text batch shape\", output_text_batch.shape)\n",
    "\n",
    "print(\"Test Image batch shape\", test_image_batch.shape)\n",
    "print(\"Test Text batch shape\", test_text_batch.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e94c906e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Entire Autoencoder Model from the Disk\n",
      "Loaded Encoder Model from the Disk\n",
      "Loaded Decoder Model from the Disk\n"
     ]
    }
   ],
   "source": [
    "# loading the saved models\n",
    "\n",
    "json_file = open(\"../model/autoencoder_model_test.json\", \"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "ae_sep_output = model_from_json(loaded_model_json)\n",
    "ae_sep_output.load_weights(\"../model/autoencoder_model_test.h5\")\n",
    "print(\"Loaded Entire Autoencoder Model from the Disk\")\n",
    "\n",
    "# load the encoding architecture and weights\n",
    "json_file = open(\"../model/encoder_model_test.json\", \"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "encoding_model = model_from_json(loaded_model_json)\n",
    "encoding_model.load_weights(\"../model/encoder_model_test.h5\")\n",
    "print(\"Loaded Encoder Model from the Disk\")\n",
    "\n",
    "# load the decoding architecture and weights\n",
    "json_file = open(\"../model/decoder_model_test.json\", \"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "decoding_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "decoding_model.load_weights(\"../model/decoder_model_test.h5\")\n",
    "print(\"Loaded Decoder Model from the Disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b409f7b5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - 2s 5ms/step\n",
      "Predicted Y is Ready. Shape :  (9810, 12)\n",
      "True Y is Ready. Shape : (9810, 12)\n",
      "Predicted Array shape  (9810, 16, 16, 3)\n",
      "True Array shape  (9810, 16, 16, 3)\n",
      "Mean MSE 5.6216087\n",
      "Median MSE 1.4626559\n"
     ]
    }
   ],
   "source": [
    "predicted_image, predicted_text = ae_sep_output.predict(\n",
    "    [test_image_batch, test_text_batch]\n",
    ")\n",
    "y_pred = [np.where(text > 0.5, 1, 0) for text in predicted_text]\n",
    "y_pred = np.array(y_pred)\n",
    "print(\"Predicted Y is Ready. Shape : \", y_pred.shape)\n",
    "\n",
    "y_true = test_text_batch\n",
    "y_true = np.array(y_true)\n",
    "print(\"True Y is Ready. Shape :\", y_true.shape)\n",
    "\n",
    "true_image = []\n",
    "for i in range(len(test_image_batch)):\n",
    "    current_image = test_image_batch[i]\n",
    "    current_image_centre = test_image_batch[i][16 : 16 + 16, 16 : 16 + 16, :]\n",
    "    true_image.append(current_image_centre)\n",
    "true_image = np.array(true_image)\n",
    "print(\"Predicted Array shape \", predicted_image.shape)\n",
    "print(\"True Array shape \", true_image.shape)\n",
    "\n",
    "mse_dist = []\n",
    "for idx in range(len(true_image)):\n",
    "    y_true_image = true_image[idx]\n",
    "    y_true_image = y_true_image.reshape(16, 16, 3)\n",
    "\n",
    "    y_pred_image = predicted_image[idx]\n",
    "    y_pred_image = y_pred_image.reshape(16, 16, 3)\n",
    "\n",
    "    mse_dist.append(np.mean(np.subtract(y_true_image, y_pred_image) ** 2))\n",
    "\n",
    "print(\"Mean MSE\", np.mean(mse_dist))\n",
    "print(\"Median MSE\", np.median(mse_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3bba438",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Macro Label Based Precision 0.7392793987621573\n",
      "Macro Label Based Recall 0.749900911613159\n",
      "Macro Label Based Accuracy 0.7391803103753164\n",
      "\n",
      "Micro Label Based Precision 0.999597017932702\n",
      "Micro Label Based Recall 0.9993956486704271\n",
      "Micro Label Based Accuracy 0.9989931534434152\n",
      "\n",
      "Example Based Precision 0.9996941896024465\n",
      "Example Based Recall 0.9996941896024465\n",
      "Example Based Accuracy 0.9996941896024465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amalalabdulkarim/Library/CloudStorage/Dropbox/Mac (2)/Downloads/tile_embeddings-main/src/utils/evaluation_metrics/multilabel/label_based.py:32: RuntimeWarning: invalid value encountered in divide\n",
      "  sum_precision=np.nansum(p_n/p_d)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMacro Label Based Precision\", precision_macro(y_true, y_pred))\n",
    "print(\"Macro Label Based Recall\", recall_macro(y_true, y_pred))\n",
    "print(\"Macro Label Based Accuracy\", accuracy_macro(y_true, y_pred))\n",
    "\n",
    "print(\"\\nMicro Label Based Precision\", precision_micro(y_true, y_pred))\n",
    "print(\"Micro Label Based Recall\", recall_micro(y_true, y_pred))\n",
    "print(\"Micro Label Based Accuracy\", accuracy_micro(y_true, y_pred))\n",
    "\n",
    "print(\"\\nExample Based Precision\", example_based_precision(y_true, y_pred))\n",
    "print(\"Example Based Recall\", example_based_recall(y_true, y_pred))\n",
    "print(\"Example Based Accuracy\", example_based_accuracy(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
